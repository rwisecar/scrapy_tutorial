import scrapy


class QuotesSpider(scrapy.Spider):
    """Creates a spider that will crawl and scrape your named urls.
    name is the name of your spider. It must be unique."""

    name = "quotes"
    start_urls = [
        'http://quotes.toscrape.com/page/1/',
        'http://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        """Parses the response object and extracts data as dicts.
        Saves the response body in a txt file.
        Name of txt file is generated by the page number in the url.
        Parse is Scrapy's default callback method.
        It will be called for requests even without an explicit callback.
        The loop here uses css selectors on the response object to create
        a dictionary of items, captured by selector. This way, when the spider
        crawls through html, it will only return the exact things you're
        looking for."""
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').extract_first(),
                'author': quote.css('span small::text').extract_first(),
                'tags': quote.css('div.tags a.tag::text').extract(),
            }
        next_page = response.css('li.next a::attr(href)').extract_first()
        if next_page is not None:
            next_page = response.urljoin(next_page)
            yield scrapy.Request(next_page, callback=self.parse)
